{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeedcdd0-79c1-4553-80c6-6d1c2cb6a9cf",
   "metadata": {},
   "source": [
    "# 04 Continous X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93df439-e7a3-4ae1-ad76-29eb467aa27f",
   "metadata": {},
   "source": [
    "> The most powerful tool we have as developers is automation.â€ ~ Scott Hanselman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9101c01-d64c-41fc-8983-f80dc08cf061",
   "metadata": {},
   "source": [
    "![continuous_x](https://miro.medium.com/max/4800/1*WsbCzcT3HWRJ4SspEl-qdg.jpeg)\n",
    "\n",
    "**Source:** Found on a [Medium](https://devopsdiaries.williamtsoi.net/continuous-delivery-in-cartoons-d67bbd6b6954) post where the author credits Nhan Ngo for the creation of this image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25273b-c95b-4f7a-9ea7-3e91cf61d38a",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2acffc-d676-4046-aeed-e20000e80363",
   "metadata": {},
   "source": [
    "1. [Overview](#1.-Overview)\n",
    "2. [Learning Outcomes](#2.-Learning-Outcomes)\n",
    "3. [Tools](#3.-Tools)\n",
    "4. [Version Control]()\n",
    "    - Git\n",
    "    - dvc\n",
    "5. [Continuous Machine Learning](#3.-Testing-Code)\n",
    "    - GitHub Actions\n",
    "        - pytest-cov\n",
    "    - CML\n",
    "7. [Summary](#7.-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be00b63-63cd-4b9f-82f0-525d96e44e86",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419eea53-13e4-4d6c-9d45-b2f780bc2421",
   "metadata": {},
   "source": [
    "![automation](https://imgs.xkcd.com/comics/automation_2x.png)\n",
    "\n",
    "\n",
    "At the heart of DevOps lies automation. While the word rolls off the tongue quite easily, accomplishing it in the software engineering world can be quite challenging. To manage the complexity, engineers have developed a system called, Continuous Delivery (CD). At its core, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b78738-a8be-4d2b-b87f-8e4e933319a6",
   "metadata": {},
   "source": [
    "## 2. Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a2a84-7ff6-44f1-a42e-72d1613c9f07",
   "metadata": {},
   "source": [
    "Before we get started, let's go over the learning outcomes for this section of the workshop.\n",
    "\n",
    "By the end of this lesson you will be able to,\n",
    "1. Discuss what ETL and ELT Pipelines are.\n",
    "2. Understand how to read and combine data that comes from different sources.\n",
    "3. Create data pipelines using pandas and prefect.\n",
    "4. Understand how to visualize the pipelines you create to help you with their development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865697c-4dfb-4904-88ee-793decb510ff",
   "metadata": {},
   "source": [
    "## 3. Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020d0e3-788d-44fe-83d0-0356356e1471",
   "metadata": {},
   "source": [
    "![cartoon]()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad1811-a5fb-499a-aa56-5da69dd2701f",
   "metadata": {},
   "source": [
    "## 4. Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce4627-1abb-42ca-bb3d-48c961d8600e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a402d3ea-72ea-4bea-9e0d-d62b36faced1",
   "metadata": {},
   "source": [
    "### 4.1 Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc5db4-2555-4fac-ae27-823449803c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df676238-85a5-4e21-acbe-e7a05a97c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/our_pyconza_proj/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5013703f-786f-4228-9c8b-bf87b7e94d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaconda\t\t\t Documents\t      Pictures\t TresoritDrive\n",
      "aura-theme.dconf\t\t Downloads\t      Postman\t Tresors\n",
      "balenaEtcher-1.7.9-x64.AppImage  Music\t\t      Public\t Videos\n",
      "bank_statement_sept2022.pdf\t new_file.pdf\t      R\n",
      "cba_bank_statement_sept2022.pdf  nodesource_setup.sh  snap\n",
      "Desktop\t\t\t\t our_pyconza_proj     Templates\n"
     ]
    }
   ],
   "source": [
    "!ls ~/our_pyconza_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03c69c-e2bc-4e7e-bc2f-7c0d97d71bdf",
   "metadata": {},
   "source": [
    "Let's go over the next steps together.\n",
    "\n",
    "1. Open a new terminal in your editor of choice.\n",
    "2. Activate the same environment you have been using for this session `conda activate environment our_environment`\n",
    "3. Navigate to the new folder `cd ~/our_pyconza_proj`\n",
    "4. Copy our src files into the folder `cp pycon_za22_data_devops/src/*.py ~/our_pyconza_proj`\n",
    "5. Initialize a new git repository with `git init`\n",
    "6. Navigate to GitHub, log in, and create a new repository by clicking on top right-hand corner.\n",
    "7. Add a `README.md` file with `echo \"# pycon-za-test\" >> README.md`\n",
    "8. Let's start tracking our files `git status && git add .`\n",
    "9. Let's commit our changes `git commit -m \"Our first commit\"`\n",
    "10. Now let's push our changes to our remote repository \n",
    "    - First we need to add it with `git remote add origin https://github.com/ramonpzg/pycon-za-test.git` or with ssh `git remote add origin git@github.com:ramonpzg/pycon-za-test.git`\n",
    "    - Then we can push our changes with `git push -u origin master`\n",
    "    - Note: You might get an authentication error if this is the first time you are pushing changes to GitHub. To bypass this momentarily, go to right-hand corner and click on your profile icon and then go to,\n",
    "        - `Settings` > `Developer settings` > `Personal access tokens` > `Generate new token`.\n",
    "        - Then, for the purpose of this tutorial only, click on all of them and then generate the token.\n",
    "        - Copy it somewhere safe as you might need it more than once.\n",
    "        - Try pushing your changes again and use the code when prompted\n",
    "\n",
    "Great now that we got set up tracking our code, let's get going tracking our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3435e-66ba-485c-9da3-2c5a6d8c4dfa",
   "metadata": {},
   "source": [
    "### 4.2 Data Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c5f2e4-c5ec-4627-8cb5-c80f3eb2f67e",
   "metadata": {},
   "source": [
    "Let's get started with dvc\n",
    "\n",
    "1. Let's first create a data folder with a \"fake\" remote_storage init `mkdir -p data/remote_storage`\n",
    "2. Run the `get_data.py function`\n",
    "3. initialise our repository with `dvc init`\n",
    "4. Add \"fake remote\" storage with `dvc remote add -d our_storage data/remote_storage`\n",
    "5. Let's add our first file with `dvc add data/02_part/raw/SeoulBikeData.csv`\n",
    "6. We can now start stracking a metadata about our data to version control it and manipulate where it goes. `git add data/02_part/raw/.gitignore data/02_part/raw/SeoulBikeData.csv.dvc`\n",
    "7. Commit changes and push `git commit -m \"the first dataset\" && git push`\n",
    "8. Let's track our data with dvc by using\n",
    "    - `dvc status` # to check what's up\n",
    "    - `dvc commit` # to commit all of the data in our repo\n",
    "    - `dvc push` # to move the data to our not so remote repo for this demo\n",
    "9. Now let's start creating our pipeline.\n",
    "    1. Let's remove our data again with `rm -rf data/02_part` to see the full example\n",
    "    2. `dvc run -n get_data -d src/get_data.py -o data/02_part/raw/SeoulBikeData.csv python src/get_data.py`\n",
    "    3. Two files got created, one is `dvc.yml` and the other is `dvc.lock`. The former keeps track of the pipeline we started creating with `dvc run`, and the latter contains less human friendly quotes (hashes and other metadata)\n",
    "    4. We can start tracking `git add data/02_part/raw/.gitignore dvc.lock dvc.yaml`\n",
    "    5. Commit incrementally `git commit -m \"initial steps of our pipeline\"` and push `git push`\n",
    "    6. Let's keep adding to our pipeline `dvc run -n prepare -d src/prepare_data.py -d data/02_part/raw/SeoulBikeData.csv -o data/02_part/interim/clean_data.parquet python src/prepare_data.py`\n",
    "    7. Now we can use `dvc config core.autostage true` to stop adding each step individually.\n",
    "    8. Another one `dvc run -n split_data -d src/split_data.py -d data/02_part/interim/clean_data.parquet -o data/02_part/processed/train.parquet -o data/02_part/processed/test.parquet python src/split_data.py`\n",
    "    9. Another one `dvc run -n train -d src/train_model.py -d data/02_part/processed/train.parquet -o models/rf_model.pkl python src/train_model.py`\n",
    "    10. Last one `dvc run -n evaluate -d src/evaluate_model.py -d models/rf_model.pkl -d data/02_part/processed/test.parquet -M reports/metrics.json python src/evaluate_model.py`\n",
    "    11. We can evaluate what our dag of steps looks like with `dvc dag`.\n",
    "    12. Now we can run it with `dvc repro`. If we make any changes to a step in the pipeline, the previous steps that were not changed will not get rerun as their ourput gets cached in memory.\n",
    "    13. Lastly, let's keep track of everything `git add . && git commit -m \"pipeline ready\" && git push`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbff53-aae1-4e30-91a9-0c8a8f895fe2",
   "metadata": {},
   "source": [
    "## 5. CI/CD Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252480c-11b6-4cb2-8ed9-be21c5290552",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e68a5c2-4041-4f33-baeb-9502d8a8541a",
   "metadata": {},
   "source": [
    "### 5.1 GitHub Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89399958-6cf9-4873-a7c3-add716a0e435",
   "metadata": {},
   "source": [
    "![gh_actions](https://svrooij.io/assets/images/github-actions-banner.png)\n",
    "\n",
    "Explain what it is\n",
    "\n",
    "Create a `mypy` GitHub Actions wokflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc33a435-a198-478e-81c1-2eafb72cf829",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/our_pyconza_proj/.github/workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280affc6-d57f-4f44-864e-74cfd6a37007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ramonperez/our_pyconza_proj/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/our_pyconza_proj/requirements.txt\n",
    "\n",
    "pandas\n",
    "scikit-learn\n",
    "numpy\n",
    "flake8\n",
    "black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20263eb8-f3c8-4819-83dd-d9fe993a349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ramonperez/our_pyconza_proj/.github/workflows/demo_pipe.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/our_pyconza_proj/.github/workflows/demo_pipe.yml\n",
    "\n",
    "name: PyCon ZA Demo\n",
    "\n",
    "on: [push]\n",
    "\n",
    "jobs:\n",
    "  build:\n",
    "\n",
    "    runs-on: ubuntu-latest\n",
    "    strategy:\n",
    "      matrix:\n",
    "        python-version: [\"3.9\", \"3.10\"]\n",
    "\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Set up Python ${{ matrix.python-version }}\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: ${{ matrix.python-version }}\n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          python -m pip install --upgrade pip\n",
    "          pip install -r requirements.txt\n",
    "      - name: Lint with flake8\n",
    "        run: |\n",
    "          # stop the build if there are Python syntax errors or undefined names\n",
    "          # flake8 ./src/get_data.py --count --select=E9,F63,F7,F82 --show-source --statistics\n",
    "          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide\n",
    "          flake8 ./src/get_data.py --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics\n",
    "      - name: Reformat with black\n",
    "        run: |\n",
    "          black ./src/split_data.py\n",
    "      - name: Check types with mypy\n",
    "        run: |\n",
    "          mypy ./src/prepare_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60718702-435a-4dfa-b998-0a8d14fb9e15",
   "metadata": {},
   "source": [
    "Time to test our pipeline\n",
    "1. Run `git status`\n",
    "2. Add files `git add .`\n",
    "3. Commit and push `git commit -m \"added CI and requirements.txt\" && git push`\n",
    "4. Immediately go to the **Actions** tab in your repo and then click on **PyCon ZA Demo** > **your commit message** > **build 3.10**, and you will be able to evaluate what happened inside our workflows.\n",
    "\n",
    "Congrats! You just ran your first pipeline ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4437695-ea87-46d5-9510-49d142b02839",
   "metadata": {},
   "source": [
    "### 5.2 Continuous Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9fcf3-d8ab-44c8-8c77-64b7d3474720",
   "metadata": {},
   "source": [
    "Now it is time to create a workflow for our machine learning models.\n",
    "\n",
    "Steps\n",
    "1. git checkout -b new_params_v1\n",
    "2. Change Random Forests Parameters\n",
    "3. dvc status\n",
    "4. dvc repro\n",
    "5. dvc status\n",
    "6. dvc push\n",
    "7. dvc metrics show\n",
    "8. dvc metrics diff --show-md master\n",
    "9. git add .\n",
    "10. git commit -m \"Testing New Params\"\n",
    "11. git push --set-upstream origin new_params_v1\n",
    "12. git push\n",
    "13. mkdir .github/workflows\n",
    "14. Add\n",
    "\n",
    "```yaml\n",
    "\n",
    "name: bikes-pipeline-test # (1)\n",
    "on: push # (2)\n",
    "jobs: # (3)\n",
    "  run: # (4)\n",
    "    runs-on: [ubuntu-latest] # (5)\n",
    "    container: docker://dvcorg/cml:0-dvc2-base1 # (6)\n",
    "    steps: # (7)\n",
    "      - uses: actions/checkout@v2 # (8)\n",
    "      - name: cml_run # (9)\n",
    "        env: # (10)\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }} # (11)\n",
    "          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }} # (12)\n",
    "          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }} # (13)\n",
    "        run: | # (14)\n",
    "          pip install -r requirements.txt # (15)\n",
    "          \n",
    "          dvc repro # (16)\n",
    "          dvc push # (17)\n",
    "          git fetch --prune # (18)\n",
    "\n",
    "          echo \"# CML Report\" > report.md # (19)\n",
    "          dvc metrics diff --show-md master >> report.md # (20)\n",
    "          cml-send-comment report.md # (21)\n",
    "```\n",
    "\n",
    "The name of our CI/CD pipeline.\n",
    "Indicates to GitHub that the pipeline should run every time we push changes to our repository.\n",
    "Indicates steps and dependencies that should run on push.\n",
    "Run what follows.\n",
    "Use the latest Ubuntu operating system to test our code.\n",
    "The environment will use a container with DVC and CML already installed in it.\n",
    "Follow the next steps after the operating system and the environment have been set up.\n",
    "This action checks-out your repository under $GITHUB_WORKSPACE, so your workflow can access it.\n",
    "The name of our CML run.\n",
    "What follows are environment secrets needed for the run.\n",
    "Your GitHub access token needs to be accessible by your environment.\n",
    "Your AWS ACCESS KEY ID needs to be accessible within the run in other to push the models to s3.\n",
    "Your AWS SECRET ACCESS KEY needs to be accessible within the run in other to push the models to s3.\n",
    "Run the following commands one after the other. The | is very important.\n",
    "Install our dependencies. See this below.\n",
    "Reproduce the pipeline using our dvc.lock and dvc.yaml.\n",
    "Push the data (if it changed) and push the model to our remote repository.\n",
    "Updates all remote branches.\n",
    "Create a report markdown file.\n",
    "Add the metrics in the master branch to our report. If this were a different branch, compare the results with those in master.\n",
    "Send the report as an email/pull request.\n",
    "Create a requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e64e3ca8-1ed1-49db-9b50-b3de29d1de8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/ramonperez/our_pyconza_proj/.github/workflows/cml.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/our_pyconza_proj/.github/workflows/cml.yaml\n",
    "\n",
    "name: testing-dvc-repro\n",
    "on: [push]\n",
    "jobs:\n",
    "  run:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v2\n",
    "      - uses: actions/setup-python@v2\n",
    "      - uses: iterative/setup-cml@v1\n",
    "        with:\n",
    "          version: '0.18.0'\n",
    "      - uses: iterative/setup-dvc@v1\n",
    "      - name: train_model\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "          dvc dag\n",
    "          dvc repro\n",
    "          dvc push\n",
    "          echo \"# My Report\" > report.md\n",
    "          dvc metrics show --show-md >> report.md\n",
    "          dvc dag >> report.md\n",
    "          cml send-comment report.md\n",
    "          cml comment create --publish report.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a1bf5-88db-4ea5-bbfa-8e3a5a275719",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f1493c-ffb3-4984-95ca-67d8d2846fc3",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7dfad-9f87-4535-82da-277a713ddac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
